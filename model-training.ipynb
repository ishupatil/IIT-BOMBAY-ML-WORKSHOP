{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2bb54ba",
   "metadata": {},
   "source": [
    "## Lab for Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5e0019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6962cc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Generate Malformed Dataset\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fc81e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset\n",
    "data = {\n",
    "    'Age': [25, 38, np.nan, 45, -1, 120, 34, None, 29, 50],\n",
    "    'Salary ($)': [50000, 60000, 75000, None, 120000, 45000, 70000, 1000000, None, 62000],\n",
    "    'Department': ['HR', 'Sales', 'HR', 'IT', 'IT', 'Finance', 'Sales', None, 'HR', 'Finance'],\n",
    "    'Performance': [\"Good\", \"Poor\", \"Excellent\", \"Good\", \"Poor\", None, \"Average\", \"Poor\", \"Good\", \"Invalid\"],\n",
    "    'Promotion': [0, 1, 0, 1, 1, 0, 0, 1, 0, 0]  # Target variable (binary classification)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3d0f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Introduce duplicates and inconsistent data\n",
    "data['Salary ($)'][7] = 1000000  # Extreme outlier\n",
    "data['Department'][9] = 'Finance '  # Trailing space\n",
    "data['Performance'][9] = 'Good '  # Trailing space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3612fe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e8501c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Initial Dataset\n",
    "print(\"Malformed Dataset:\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7ffbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save initial dataset as CSV\n",
    "df.to_csv('malformed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc9c886",
   "metadata": {},
   "source": [
    "# ------------------------------------\n",
    "# 2. Data Cleaning and Transformation\n",
    "# ------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107bc4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Handle Missing Values\n",
    "df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "df['Salary ($)'].fillna(df['Salary ($)'].median(), inplace=True)\n",
    "df = df.dropna(subset=['Department', 'Performance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a407df8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Clean Categorical Data\n",
    "df['Department'] = df['Department'].str.strip()\n",
    "df['Performance'] = df['Performance'].str.strip().replace(\"Invalid\", \"Average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0553e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Handle Outliers\n",
    "# Replace negative and extreme \"Age\" values\n",
    "df['Age'] = df['Age'].apply(lambda x: max(0, min(x, 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d82bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with extreme outliers in \"Salary ($)\"\n",
    "df = df[df['Salary ($)'] < 500000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f644b50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Encode Categorical Variables\n",
    "label_encoder = LabelEncoder()\n",
    "df['Department'] = label_encoder.fit_transform(df['Department'])\n",
    "df['Performance'] = label_encoder.fit_transform(df['Performance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a10be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Normalize Numeric Data\n",
    "scaler = StandardScaler()\n",
    "df[['Age', 'Salary ($)']] = scaler.fit_transform(df[['Age', 'Salary ($)']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3c6599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Cleaned Dataset\n",
    "print(\"Cleaned Dataset:\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb0c0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------\n",
    "# 3. Model Training and Evaluation\n",
    "# -------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b01adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data into Features and Target\n",
    "X = df.drop(columns=['Promotion'])\n",
    "y = df['Promotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe609ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Dataset into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb186a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest Classifier\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72c5cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Predictions\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53071a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model Performance\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nAccuracy Score:\")\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662beed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------\n",
    "# 4. Save the Model (Optional)\n",
    "# --------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c731a08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model for later use\n",
    "joblib.dump(model, 'trained_model.pkl')\n",
    "\n",
    "print(\"\\nModel saved as 'trained_model.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86189af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "importances = model.feature_importances_\n",
    "feature_names = X.columns\n",
    "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"Feature Importance:\")\n",
    "display(feature_importance_df)\n",
    "\n",
    "# Drop low-importance features (if any have near-zero importance)\n",
    "low_importance_features = feature_importance_df[feature_importance_df['Importance'] < 0.01]['Feature']\n",
    "X_train = X_train.drop(columns=low_importance_features)\n",
    "X_test = X_test.drop(columns=low_importance_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26375602",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Grid Search\n",
    "grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42), \n",
    "                           param_grid=param_grid, \n",
    "                           cv=3, \n",
    "                           n_jobs=-1, \n",
    "                           verbose=2)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Use the best parameters for the model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the tuned model\n",
    "y_pred_tuned = best_model.predict(X_test)\n",
    "print(\"\\nTuned Model Accuracy Score:\", accuracy_score(y_test, y_pred_tuned))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cf536c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30affa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "print(\"XGBoost successfully installed!\")\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Train an XGBoost model\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate XGBoost model\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "print(\"\\nXGBoost Model Accuracy Score:\", accuracy_score(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d85c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add interaction features\n",
    "X['Age_Salary'] = X['Age'] * X['Salary ($)']\n",
    "\n",
    "# Re-split the data after adding features\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a765f758",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(best_model, X, y, cv=3, scoring='accuracy')\n",
    "print(\"Cross-Validation Accuracy Scores:\", cv_scores)\n",
    "print(\"Mean Accuracy:\", np.mean(cv_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2400b41e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Overfitting: The model might be overfitting on some folds, achieving perfect accuracy (1.0) but failing on others (0.0 or 0.5).\n",
    "Data Issues: Class imbalance, small dataset size, or noise in the data could be causing performance inconsistencies.\n",
    "Cross-Validation Splits: Uneven splits during cross-validation could result in imbalanced training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81eac98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
